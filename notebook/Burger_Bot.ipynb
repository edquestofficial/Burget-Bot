{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edquestofficial/Burget-Bot/blob/main/notebook/Burger_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqw7y_WCK6eh"
      },
      "source": [
        "# **Transforming Food Ordering with Next-Gen AI Chatbots!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV8FDEw1as6l"
      },
      "source": [
        "![alt text](../images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxn294aCLVCg"
      },
      "source": [
        "### **Problem Statement:**\n",
        "\n",
        "Traditional food order chatbots often fail to deliver a personalized and engaging experience, leaving customers unsatisfied. These limitations manifest as repetitive interactions, a lack of context awareness, and difficulty understanding user queries. This frustration translates to lost business and a negative brand perception. Existing online ordering systems, while offering some convenience, often lack the ability to cater to specific dietary needs or preferences. This inflexibility hinders personalization and limits customer satisfaction. There's a pressing need for a cutting-edge solution that can address these shortcomings. We require a system that understands and responds to user queries in real-time, offering dynamic and creative interactions.\n",
        "\n",
        "### **Solution:**\n",
        "\n",
        "**Bun Buddy - A Generative AI Chatbot for Burger Shop:**\n",
        "\n",
        "Bun Buddy aims to address the limitations of current burger ordering methods by leveraging the power of Generative AI technology.\n",
        "\n",
        "Here's how Bun Buddy will revolutionize the ordering experience:\n",
        "\n",
        "•\t**Personalized Interactions:** Bun Buddy will engage in friendly and natural conversations, understanding individual needs and preferences. Customers can customize their burgers precisely, catering to dietary restrictions or unique tastes.\n",
        "\n",
        "\n",
        "•\t**Real-Time Response & Context Awareness:** Bun Buddy will understand the flow of the conversation and respond accordingly, eliminating repetitive interactions and frustrations.\n",
        "\n",
        "•\t**Enhanced Efficiency:** The user-friendly interface will streamline the ordering process, leading to faster order placement and reduced wait times.\n",
        "\n",
        "•**Reduced Errors:** Eliminating human intervention minimizes the risk of order errors, ensuring customer satisfaction.\n",
        "\n",
        "By implementing Bun Buddy, Burger Shop can expect several benefits:\n",
        "\n",
        "•\t**Improved Customer Satisfaction:** Personalized interactions and a user-friendly experience will lead to happier customers.\n",
        "\n",
        "•**Increased Order Accuracy:** Eliminating human error guarantees accurate orders.\n",
        "\n",
        "•\t**Streamlined Operations:** Faster order processing leads to increased efficiency and potentially higher sales volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45IZUoGuNjof"
      },
      "source": [
        "## **Burger-Bot:**\n",
        "\n",
        "#### Let's create a burger ordering chatbot using Gradio and Gemini Pro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPd623nmas6n"
      },
      "source": [
        "![alt text](<../images/Architectural diagram.jpeg>)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFRuzJafN-bD"
      },
      "source": [
        "#### **Step 1:**\n",
        "Import and install the necessary libraries\n",
        "* Google Generative AI library allows you to work with Google's generative AI models, providing tools and interfaces for generating and managing AI content.\n",
        "* The python-dotenv library is used to load environment variables from a .env file into the system's environment variables. This is useful for managing sensitive information like API keys and configuration settings.\n",
        "* Gradio is a Python library used to create user-friendly web-based interfaces for machine learning models and other applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDfea7Iin9Iv"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "!pip install google-generativeai\n",
        "!pip instal python-dotenv\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfQnQDIAOaVR"
      },
      "source": [
        "#### **Step 2:**\n",
        "\n",
        "* Configure the Gemini API Key.\n",
        "* Initializing the model using genai.\n",
        "* Initializing the chat using model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4en1ztwJPmDG"
      },
      "outputs": [],
      "source": [
        "# Configure api_key\n",
        "genai.configure(api_key=os.getenv(\"YOUR_GEMINI_API_KEY\"))\n",
        "\n",
        "# Define Model Instance\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVHu5AflPKdH"
      },
      "source": [
        "#### **Step 3:**\n",
        "\n",
        "Create a function to send the query to the LLM and get the response in return.This function sends a message to the language model and returns the model's response.\n",
        "It takes a message as input, sends it to the chat model, and then returns the response text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwAInJ71bblI"
      },
      "outputs": [],
      "source": [
        "# Define function, which helps to execute any prompt\n",
        "def get_llm_response(message):\n",
        "    response = chat.send_message(message)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GiW7FtUPuvq"
      },
      "source": [
        "#### **Step 4:**\n",
        "\n",
        "1. Define the Basic Information for the Bot\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_iIItZBdmUv"
      },
      "outputs": [],
      "source": [
        "base_info = \"\"\"\n",
        "You are OrderBot, an automated service to collect orders for a Burger Singh Restaurant. \\\n",
        "You first greet the customer, then collects the order, \\\n",
        "and then asks if its a pickup or delivery. \\\n",
        "Please do not use your own knowladge, stick within the given context only. \\\n",
        "You wait to collect the entire order, then summarize it and check for a final \\\n",
        "time if the customer wants to add anything else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTrdmYdoQHR3"
      },
      "source": [
        "2. Define Delivery related instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mRoVmC2toPs"
      },
      "outputs": [],
      "source": [
        "delivery_info = \"\"\"If its a delivery, you ask for an address. \\\n",
        "Finally you collect the payment. \\\n",
        "Make sure to clarify all options, extras and sizes to uniquely \\\n",
        "identify the item from the menu. \\\n",
        "You respond in a short, very conversational friendly style. \\\n",
        "The menu includes\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYuNUd0dQeS-"
      },
      "source": [
        "3. Define the Menu\n",
        "   * Define available burger types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoZWcuPNdzMo"
      },
      "outputs": [],
      "source": [
        "burger_type = \"\"\"\n",
        "Desi burger for 79 Rs \\\n",
        "Maharaja burger for 179 Rs \\\n",
        "Aloo Tikki burger for 99 Rs \\\n",
        "Classic Cheese burger for 129 Rs \\\n",
        "Double Cheese burger for 179 Rs \\\n",
        "Heartattack burger for 1249 Rs \\\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nupQ19Ltas6q"
      },
      "source": [
        " * Define fries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnXOZJkceQ4N"
      },
      "outputs": [],
      "source": [
        "fries = \"45 Rs 60 Rs 80 Rs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3TYiPC_as6q"
      },
      "source": [
        "  * Define available toppings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtBUHRFLeV3w"
      },
      "outputs": [],
      "source": [
        "\n",
        "toppings = \"\"\"\n",
        "lettuce 15 Rs  \\\n",
        "tomato 15 Rs  \\\n",
        "onion 15 Rs  \\\n",
        "pickles 15 Rs  \\\n",
        "mushrooms 15 Rs  \\\n",
        "extra cheese 20 Rs  \\\n",
        "Tandoori sauce 15 Rs  \\\n",
        "peppers 10 Rs\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpGmwVewas6q"
      },
      "source": [
        "  * Define Drinks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqm7YjbVeZgS"
      },
      "outputs": [],
      "source": [
        "\n",
        "drinks = \"\"\"\n",
        "coke 60 Rs, 45 Rs, 30 Rs \\\n",
        "sprite 60 Rs, 45 Rs, 30 Rs \\\n",
        "bottled water 50 Rs \\\n",
        "dolly special chai 99 Rs \\\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bnrn_lDQ47W"
      },
      "source": [
        "#### **Step 5**\n",
        "\n",
        "* Create the Final Prompt\n",
        "    * This section initializes the context list with formatted strings containing base information,delivery information, burger type, fries, toppings, and drinks.This context will be used to generate responses from the language model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fKVZttd-ed7V"
      },
      "outputs": [],
      "source": [
        "# create prompt\n",
        "context = [f\"\"\"\n",
        "{base_info} \\\n",
        "{delivery_info} \\\n",
        "{burger_type} \\\n",
        "fries: {fries} \\\n",
        "Toppings: {toppings} \\\n",
        "Drinks: {drinks} \\\n",
        "\"\"\"]  # accumulate messages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_9Md1Das6r"
      },
      "source": [
        "* Create Welcome Message\n",
        "    * Append an empty string to the context list to represent a welcome message. This sets up the context for generating an initial response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlV4hmVSas6r"
      },
      "outputs": [],
      "source": [
        "# create welcome message\n",
        "context.append(\"\")\n",
        "response = get_llm_response(context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNRMvbJBas6r"
      },
      "source": [
        "* Define Communication Function\n",
        "    * This function defines how the chatbot will handle incoming messages.The function takes a message and history as input, updates the context with the new message,generates a response using the language model, updates the context with the response, and returns the response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_bMCRU7as6r"
      },
      "outputs": [],
      "source": [
        "# define communication function\n",
        "def bot(message, history):\n",
        "  prompt = message\n",
        "  context.append(prompt)\n",
        "  response = get_llm_response(context)\n",
        "  context.append(response)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDwdOY9aas6r"
      },
      "source": [
        "* Create Gradio Instance & Launch Gradio Chatbot\n",
        "    * Initialize a Gradio ChatInterface with the bot function as the handler for incoming messages.The examples parameter provides example messages for users to try.The title parameter sets the initial response as the title of the chat interface.\n",
        "    * Launch the Gradio interface with debugging enabled and sharing options turned on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYMRIDVnas6r"
      },
      "outputs": [],
      "source": [
        "# create gradio instance\n",
        "demo = gr.ChatInterface(fn=bot, examples=[\"🍔🍟🥤\", \"Maharaja burger/Heartattack burger\", \"fries\", \"Toppings: extra cheese/ Tandoori sauce\", \"Drinks: dolly special chai/coke/sprite\"], title=response)\n",
        "# launch gradio chatbot\n",
        "demo.launch(debug=True, share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
